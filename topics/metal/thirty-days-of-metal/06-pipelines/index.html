<!doctype html><html lang=en><head><meta charset=UTF-8><meta name=viewport content="width=device-width,initial-scale=1"><meta http-equiv=X-UA-Compatible content="ie=edge"><meta http-equiv=Accept-CH content="DPR, Viewport-Width, Width"><link rel=icon href=/logo.png type=image/gif><link rel=preconnect href=https://fonts.googleapis.com><link rel=preconnect href=https://fonts.gstatic.com crossorigin><link rel=preload as=style href="https://fonts.googleapis.com/css2?family=Alata&family=Lora:ital,wght@0,400;0,500;0,600;0,700;1,400;1,500;1,600;1,700&family=Roboto:ital,wght@0,100;0,300;0,400;0,500;0,700;0,900;1,100;1,300;1,400;1,500;1,700;1,900&display=swap"><link rel=stylesheet href="https://fonts.googleapis.com/css2?family=Alata&family=Lora:ital,wght@0,400;0,500;0,600;0,700;1,400;1,500;1,600;1,700&family=Roboto:ital,wght@0,100;0,300;0,400;0,500;0,700;0,900;1,100;1,300;1,400;1,500;1,700;1,900&display=swap" media=print onload='this.media="all"'><noscript><link href="https://fonts.googleapis.com/css2?family=Alata&family=Lora:ital,wght@0,400;0,500;0,600;0,700;1,400;1,500;1,600;1,700&family=Roboto:ital,wght@0,100;0,300;0,400;0,500;0,700;0,900;1,100;1,300;1,400;1,500;1,700;1,900&display=swap" rel=stylesheet></noscript><link rel=stylesheet href=/css/font.css media=all><meta property="og:url" content="https://bobblelaw.github.io/topics/metal/thirty-days-of-metal/06-pipelines/"><meta property="og:site_name" content="Bobble Law"><meta property="og:title" content="Bobble Law"><meta property="og:description" content="Pipelines Let’s recap what we’ve learned in the first five installments of this series.
First, we learned about how to get a device object, which lets us allocate resources and create various other objects related to command submission. Then, we talked about creating buffers, a type of resource that holds the data to be used by the GPU in fulfilling our commands. Then, we talked about how to encode commands and submit them to the GPU for execution. Last time, we started to get acquainted with shaders, the programs we write that run on the GPU itself."><meta property="og:locale" content="en_US"><meta property="og:type" content="article"><meta property="article:section" content="topics"><meta name=twitter:card content="summary"><meta name=twitter:title content="Bobble Law"><meta name=twitter:description content="Pipelines Let’s recap what we’ve learned in the first five installments of this series.
First, we learned about how to get a device object, which lets us allocate resources and create various other objects related to command submission. Then, we talked about creating buffers, a type of resource that holds the data to be used by the GPU in fulfilling our commands. Then, we talked about how to encode commands and submit them to the GPU for execution. Last time, we started to get acquainted with shaders, the programs we write that run on the GPU itself."><link rel=stylesheet href=/bootstrap-5/css/bootstrap.min.css media=all><link rel=stylesheet href=/css/header.css media=all><link rel=stylesheet href=/css/footer.css media=all><link rel=stylesheet href=/css/theme.css media=all><style>:root{--text-color:#343a40;--text-secondary-color:#6c757d;--text-link-color:#007bff;--background-color:#eaedf0;--secondary-background-color:#64ffda1a;--primary-color:#007bff;--secondary-color:#f8f9fa;--text-color-dark:#e4e6eb;--text-secondary-color-dark:#b0b3b8;--text-link-color-dark:#ffffff;--background-color-dark:#18191a;--secondary-background-color-dark:#212529;--primary-color-dark:#ffffff;--secondary-color-dark:#212529}body{font-size:1rem;font-weight:400;line-height:1.5;text-align:left}html{background-color:var(--background-color)!important}body::-webkit-scrollbar{height:0;width:8px;background-color:var(--background-color)}::-webkit-scrollbar-track{border-radius:1rem}::-webkit-scrollbar-thumb{border-radius:1rem;background:#b0b0b0;outline:1px solid var(--background-color)}#search-content::-webkit-scrollbar{width:.5em;height:.1em;background-color:var(--background-color)}</style><meta name=description content><link rel=stylesheet href=/css/single.css><script defer src=/fontawesome-6/all-6.4.2.js></script><title>| Bobble Law</title></head><body class=light><script>let localStorageValue=localStorage.getItem("pref-theme"),mediaQuery=window.matchMedia("(prefers-color-scheme: dark)").matches;switch(localStorageValue){case"dark":document.body.classList.add("dark");break;case"light":document.body.classList.remove("dark");break;default:mediaQuery&&document.body.classList.add("dark");break}</script><script>var prevScrollPos=window.pageYOffset;window.addEventListener("scroll",function(){let s=document.getElementById("profileHeader"),t=window.pageYOffset,n=!1,o=!0,i=o?prevScrollPos>t:t>0;i?s.classList.add("showHeaderOnTop"):n=!0,t===0&&(n=!0),n&&s.classList.remove("showHeaderOnTop"),prevScrollPos=t})</script><header id=profileHeader><nav class="pt-3 navbar navbar-expand-lg animate"><div class="container-fluid mx-xs-2 mx-sm-5 mx-md-5 mx-lg-5"><a class="navbar-brand primary-font text-wrap" href=/><img src=/logo.png width=30 height=30 class="d-inline-block align-top">
Bob Law</a><div><input id=search autocomplete=off class="form-control mr-sm-2 d-none d-md-block" placeholder=Search... aria-label=Search oninput=searchOnChange(event)></div><button class=navbar-toggler type=button data-bs-toggle=collapse data-bs-target=#navbarContent aria-controls=navbarContent aria-expanded=false aria-label="Toggle navigation"><svg aria-hidden="true" height="24" viewBox="0 0 16 16" width="24" data-view-component="true"><path fill-rule="evenodd" d="M1 2.75A.75.75.0 011.75 2h12.5a.75.75.0 110 1.5H1.75A.75.75.0 011 2.75zm0 5A.75.75.0 011.75 7h12.5a.75.75.0 110 1.5H1.75A.75.75.0 011 7.75zM1.75 12a.75.75.0 100 1.5h12.5a.75.75.0 100-1.5H1.75z"/></svg></button><div class="collapse navbar-collapse text-wrap primary-font" id=navbarContent><ul class="navbar-nav ms-auto text-center"><li class="nav-item navbar-text d-block d-md-none"><div class=nav-link><input id=search autocomplete=off class="form-control mr-sm-2" placeholder=Search... aria-label=Search oninput=searchOnChange(event)></div></li><li class="nav-item navbar-text"><a class=nav-link href=/#about aria-label=about>About</a></li><li class="nav-item navbar-text"><a class=nav-link href=/#experience aria-label=experience>Experience</a></li><li class="nav-item navbar-text"><a class=nav-link href=/#education aria-label=education>Education</a></li><li class="nav-item navbar-text"><a class=nav-link href=/posts title>Posts</a></li><li class="nav-item navbar-text"><a class=nav-link href=/tags title>Tags</a></li><li class="nav-item navbar-text"><a class=nav-link href=/topics title>Topics</a></li><li class="nav-item navbar-text"><div class=text-center><button id=theme-toggle><svg id="moon" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></li></ul></div></div></nav></header><div id=content><section id=single><div class=container><div class="row justify-content-center"><div class="col-sm-12 col-md-12 col-lg-9"><div class=pr-lg-4><div class="title mb-5"><h1 class="text-center mb-4"></h1><div class=text-center>Jan 1, 1010
<span id=readingTime>min read</span></div></div><article class="page-content p-2"><h1 id=pipelines>Pipelines</h1><p>Let’s recap what we’ve learned in the first five installments of this series.</p><p>First, we learned about how to get a device object, which lets us allocate resources and create various other objects related to command submission. Then, we talked about creating buffers, a type of resource that holds the data to be used by the GPU in fulfilling our commands. Then, we talked about how to encode commands and submit them to the GPU for execution. Last time, we started to get acquainted with shaders, the programs we write that run on the GPU itself.</p><p>Looking back, we’ve covered a lot of ground! Our next step is to understand how to build pipelines from our shader functions.</p><p>We will begin with the simplest kind of pipeline: <em>compute pipelines</em>. In contrast to render pipelines — which have many stages like vertex processing, rasterization, fragment processing, and so on — compute pipelines really only have one stage: “do the work.”</p><h2 id=kernel-functions>Kernel Functions</h2><p>The work done by a compute pipeline occurs in a particular kind of shader function called a <em>kernel function</em>, also called a “compute kernel” or “compute function.” Each invocation of a kernel function does a small unit of work on various data to produce an output.</p><p>For example, a kernel function might retrieve two numbers from two different input buffers, add them together, then write the result to a third buffer. Here’s what that looks like in code:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-Cpp data-lang=Cpp><span style=display:flex><span>kernel <span style=color:#66d9ef>void</span> <span style=color:#a6e22e>add_two_values</span>(constant <span style=color:#66d9ef>float</span> <span style=color:#f92672>*</span>inputsA [[buffer(<span style=color:#ae81ff>0</span>)]],
</span></span><span style=display:flex><span>                           constant <span style=color:#66d9ef>float</span> <span style=color:#f92672>*</span>inputsB <span style=color:#a6e22e>[[buffer(1)]]</span>,
</span></span><span style=display:flex><span>                           device <span style=color:#66d9ef>float</span> <span style=color:#f92672>*</span>outputs   <span style=color:#a6e22e>[[buffer(2)]]</span>,
</span></span><span style=display:flex><span>                           uint index <span style=color:#a6e22e>[[thread_position_in_grid]]</span>)
</span></span><span style=display:flex><span>{
</span></span><span style=display:flex><span>    outputs[index] <span style=color:#f92672>=</span> inputsA[index] <span style=color:#f92672>+</span> inputsB[index];
</span></span><span style=display:flex><span>}
</span></span></code></pre></div><p>Once again, ignore the syntax and instead focus on the operation being performed. We take pointers to two input buffers (<code>inputsA</code> and <code>inputsB</code>), a pointer to the output buffer (<code>outputs</code>), and an index that tells us which element to operate on. In the body of the function, we do the work of getting the two input values, add them, and write the result to the outputs.</p><p>But how do we know which index we’re operating on? We’ll get to that, but first we need to know how to construct a compute pipeline that will enable us to use this kernel function.</p><h2 id=creating-compute-pipelines>Creating Compute Pipelines</h2><p>Creating a compute pipeline is a two-stage process. Assume we already have a device and a library object (we discussed libraries in the previous entry). First, we create an <code>MTLFunction</code> object referring to the kernel function.</p><p>As we saw last time, we can create a function object by asking for it by name from the library:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-Swift data-lang=Swift><span style=display:flex><span><span style=color:#66d9ef>let</span> kernelFunction = library.makeFunction(name: <span style=color:#e6db74>&#34;add_two_values&#34;</span>)<span style=color:#f92672>!</span>
</span></span></code></pre></div><p>We then create the compute pipeline by passing the function to the <code>makeComputePipelineState(function:)</code> method on our device:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-Swift data-lang=Swift><span style=display:flex><span><span style=color:#66d9ef>let</span> computePipeline = <span style=color:#66d9ef>try</span> device.makeComputePipelineState(function: kernelFunction)
</span></span></code></pre></div><p>The <code>computePipeline</code> variable now holds a reference to a <code>compute pipeline state</code> object, which conforms to the <code>MTLComputePipelineState</code> protocol. How do we use such an object?</p><h2 id=organizing-compute-work>Organizing Compute Work</h2><p>GPUs are built to operate in parallel on many pieces of data at the same time. When we write vertex and fragment functions, we are writing code that might be executed concurrently on dozens of vertices or fragments. This massive concurrency is part of what makes GPUs so efficient.</p><p>When we write kernel functions, we aren’t necessarily processing vertices or pixels, so we need some other way of organizing work. This is called a <em>grid</em>.</p><p>A grid is nothing more than a block of work. Grids can be one-, two-, or three-dimensional. You can think of the dimensions of a grid as corresponding to nested <code>for</code> loops. A one-dimensional grid is a single <code>for</code> loop; a two-dimensional-grid is a nested <code>for</code> loop; and a three-dimensional grid is a doubly-nested <code>for</code> loop.</p><p>In the same way that we might use indices such as <code>i</code>, <code>j</code>, and <code>k</code> to index the iterations of a loop, we uniquely identify the index of a piece of work through its position in the grid.</p><p>So how do we define grids in code and use them to get work done?</p><p>First, we need to understand that each invocation of our kernel function corresponds to a unique <em>thread</em> of execution. We subdivide our grid into groups of threads — called <em>threadgroups</em> — that are intended to execute concurrently. Like grids themselves, threadgroups can be one-, two-, or three-dimensional. The dimensions of our grid are then the size of the threadgroup multiplied by the number of threadgroups we want to execute.</p><p>Generally, the number of threads in a threadgroup should be a multiple of 32 or 64 (assuming there are at least that many invocations needed to get the job done). More specifically, it should be a multiple of the compute pipeline state’s <u>threadExecutionWidth</u> property. <u>Selecting the best threadgroup size</u> is sometimes a matter of experimentation and won’t matter for the small examples I’m showing here.</p><p>Suppose we have two arrays containing 256 floats each and we want to sum them up. Since arrays are one-dimensional data structures, we might define our threadgroup size like this</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-Swift data-lang=Swift><span style=display:flex><span><span style=color:#66d9ef>let</span> threadsPerThreadgroup = MTLSize(width: <span style=color:#ae81ff>32</span>, height: <span style=color:#ae81ff>1</span>, depth: <span style=color:#ae81ff>1</span>)
</span></span></code></pre></div><p>Each threadgroup will have 32 threads, allowing the kernel function to run up to 32 times concurrently.</p><p>We now need to select a threadgroup count that, when multiplied by the threadgroup size, equals the total number of array elements. 256/32=8, so we need 8 threadgroups:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-Swift data-lang=Swift><span style=display:flex><span><span style=color:#66d9ef>let</span> threadgroupCount = MTLSize(width: <span style=color:#ae81ff>8</span>, height: <span style=color:#ae81ff>1</span>, depth: <span style=color:#ae81ff>1</span>)
</span></span></code></pre></div><p>Thus our total grid size is 256×1×1.</p><h2 id=encoding-compute-work>Encoding Compute Work</h2><p>Now that we know how to organize work into grids, let’s talk about using our compute pipeline to do the work.</p><p>First, let’s allocate a few buffers to hold the input and output values:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-Swift data-lang=Swift><span style=display:flex><span><span style=color:#66d9ef>let</span> elementCount = <span style=color:#ae81ff>256</span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>let</span> inputBufferA = device.makeBuffer(length: MemoryLayout&lt;Float&gt;.stride <span style=color:#f92672>*</span> elementCount,
</span></span><span style=display:flex><span>                                     options: .storageModeShared)<span style=color:#f92672>!</span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>let</span> inputBufferB = device.makeBuffer(length: MemoryLayout&lt;Float&gt;.stride <span style=color:#f92672>*</span> elementCount,
</span></span><span style=display:flex><span>                                     options: .storageModeShared)<span style=color:#f92672>!</span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>let</span> outputBuffer = device.makeBuffer(length: MemoryLayout&lt;Float&gt;.stride <span style=color:#f92672>*</span> elementCount,
</span></span><span style=display:flex><span>                                     options: .storageModeShared)<span style=color:#f92672>!</span>
</span></span></code></pre></div><p>Then, let’s populate the buffers with some values so we can validate that the operation completed successfully.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-Swift data-lang=Swift><span style=display:flex><span><span style=color:#66d9ef>let</span> inputsA = inputBufferA.contents().assumingMemoryBound(to: Float.<span style=color:#66d9ef>self</span>)
</span></span><span style=display:flex><span><span style=color:#66d9ef>let</span> inputsB = inputBufferB.contents().assumingMemoryBound(to: Float.<span style=color:#66d9ef>self</span>)
</span></span><span style=display:flex><span><span style=color:#66d9ef>for</span> i <span style=color:#66d9ef>in</span> <span style=color:#ae81ff>0.</span>.&lt;elementCount {
</span></span><span style=display:flex><span>    inputsA[i] = Float(i)
</span></span><span style=display:flex><span>    inputsB[i] = Float(elementCount <span style=color:#f92672>-</span> i)
</span></span><span style=display:flex><span>}
</span></span></code></pre></div><p>Input buffer A contains the numbers 0 to 255 in sequence, while input buffer B contains the numbers 256 to 1 in reverse order. If we sum them up pairwise, each value in the output will therefore be 256.</p><p>As we saw previously, we send commands to the GPU in parcels called command buffers. Assuming we have a command queue already, we can ask it to create a command buffer:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-Swift data-lang=Swift><span style=display:flex><span><span style=color:#66d9ef>let</span> commandBuffer = commandQueue.makeCommandBuffer()<span style=color:#f92672>!</span>
</span></span></code></pre></div><p>We now create a new kind of encoder object: a compute command encoder. As the name suggests, we use a compute command encoder to encode compute work for the GPU.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-Swift data-lang=Swift><span style=display:flex><span><span style=color:#66d9ef>let</span> commandEncoder = commandBuffer.makeComputeCommandEncoder()<span style=color:#f92672>!</span>
</span></span></code></pre></div><p>Unlike the blit command encoder we saw previously, compute and render command encoders require a pipeline state object. This is because render commands and compute commands both execute shader functions, and a pipeline state object contains one or more compiled shader functions.</p><p>We set the previously created compute pipeline state on the command encoder before asking it to do any work:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-Swift data-lang=Swift><span style=display:flex><span>commandEncoder.setComputePipelineState(computePipeline)
</span></span></code></pre></div><p>We then set the inputs of our kernel function. Each buffer parameter is “bound” by calling the <code>setBuffer(:offset:index:)</code> method. Note that the index parameter of each buffer argument matches the index in the <code>buffer</code> attribute in the shader code.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-Swift data-lang=Swift><span style=display:flex><span>commandEncoder.setBuffer(inputBufferA, offset: <span style=color:#ae81ff>0</span>, index: <span style=color:#ae81ff>0</span>)
</span></span><span style=display:flex><span>commandEncoder.setBuffer(inputBufferB, offset: <span style=color:#ae81ff>0</span>, index: <span style=color:#ae81ff>1</span>)
</span></span><span style=display:flex><span>commandEncoder.setBuffer(outputBuffer, offset: <span style=color:#ae81ff>0</span>, index: <span style=color:#ae81ff>2</span>)
</span></span></code></pre></div><p>The command to execute a grid of compute work is called a <em>dispatch</em>, so we use the <code>dispatchThreadgroups(_:, threadsPerThreadgroup:)</code> method to tell the encoder to encode a command to dispatch our grid:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-Swift data-lang=Swift><span style=display:flex><span>commandEncoder.dispatchThreadgroups(threadgroupCount,
</span></span><span style=display:flex><span>                                    threadsPerThreadgroup: threadsPerThreadgroup)
</span></span><span style=display:flex><span>                                    ```
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>Since that<span style=color:#960050;background-color:#1e0010>’</span>s all the work we want to encode, we then call `endEncoding` on the encoder:
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>```Swift
</span></span><span style=display:flex><span>commandEncoder.endEncoding()
</span></span></code></pre></div><p>As before, if we want to see the results of our work, we can print out the elements of the output buffer once we’re informed the work is done.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-Swift data-lang=Swift><span style=display:flex><span>commandBuffer.addCompletedHandler { <span style=color:#66d9ef>_</span> <span style=color:#66d9ef>in</span>
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>let</span> outputs = outputBuffer.contents().assumingMemoryBound(to: Float.<span style=color:#66d9ef>self</span>)
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>for</span> i <span style=color:#66d9ef>in</span> <span style=color:#ae81ff>0.</span>.&lt;elementCount {
</span></span><span style=display:flex><span>        print(<span style=color:#e6db74>&#34;Output element </span><span style=color:#e6db74>\(</span>i<span style=color:#e6db74>)</span><span style=color:#e6db74> is </span><span style=color:#e6db74>\(</span>outputs[i]<span style=color:#e6db74>)</span><span style=color:#e6db74>&#34;</span>)
</span></span><span style=display:flex><span>    }
</span></span><span style=display:flex><span>}
</span></span><span style=display:flex><span>commandBuffer.commit()
</span></span></code></pre></div><p>On my machine, this prints:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-cmd data-lang=cmd><span style=display:flex><span>Output element 0 is 256.0
</span></span><span style=display:flex><span>Output element 1 is 256.0
</span></span><span style=display:flex><span>Output element 2 is 256.0
</span></span><span style=display:flex><span>⋮
</span></span><span style=display:flex><span>Output element 253 is 256.0
</span></span><span style=display:flex><span>Output element 254 is 256.0
</span></span><span style=display:flex><span>Output element 255 is 256.0
</span></span></code></pre></div><p>Success!</p><p>In this article, we learned how to write kernel functions and ask the device to compile them into compute pipeline states. We then learned about how to encode compute work that operates on multiple buffers.</p><p>At long last, we’re ready to start drawing shapes! Next time, we’ll introduce render pipeline states and draw calls, opening a whole new dimension of possibilities.</p></article></div></div><div class="col-sm-12 col-md-12 col-lg-3"><div id=stickySideBar class=sticky-sidebar><aside class=toc><h5>Table Of Contents</h5><div class=toc-content><nav id=TableOfContents><ul><li><a href=#kernel-functions>Kernel Functions</a></li><li><a href=#creating-compute-pipelines>Creating Compute Pipelines</a></li><li><a href=#organizing-compute-work>Organizing Compute Work</a></li><li><a href=#encoding-compute-work>Encoding Compute Work</a></li></ul></nav></div></aside><aside class=social><h5>Social</h5><div class=social-content><ul class=list-inline><li class="list-inline-item text-center"><a target=_blank href="https://www.linkedin.com/shareArticle?mini=true&url=https%3a%2f%2fbobblelaw.github.io%2ftopics%2fmetal%2fthirty-days-of-metal%2f06-pipelines%2f"><i class="fab fa-linkedin"></i></a></li><li class="list-inline-item text-center"><a target=_blank href="https://twitter.com/share?text=&url=https%3a%2f%2fbobblelaw.github.io%2ftopics%2fmetal%2fthirty-days-of-metal%2f06-pipelines%2f"><i class="fab fa-twitter"></i></a></li><li class="list-inline-item text-center"><a target=_blank href="https://api.whatsapp.com/send?text=: https%3a%2f%2fbobblelaw.github.io%2ftopics%2fmetal%2fthirty-days-of-metal%2f06-pipelines%2f"><i class="fab fa-whatsapp"></i></a></li><li class="list-inline-item text-center"><a target=_blank href='mailto:?subject=&amp;body=Check%20out%20this%20site https%3a%2f%2fbobblelaw.github.io%2ftopics%2fmetal%2fthirty-days-of-metal%2f06-pipelines%2f'><i class="fa fa-envelope"></i></a></li></ul></div></aside></div></div></div><div class=row><div class="col-sm-12 col-md-12 col-lg-9 p-4"></div></div></div><button class="p-2 px-3" onclick=topFunction() id=topScroll>
<i class="fas fa-angle-up"></i></button></section><div class=progress><div id=scroll-progress-bar class=progress-bar role=progressbar aria-valuenow=0 aria-valuemin=0 aria-valuemax=100></div></div><script src=/js/scrollProgressBar.js></script><script>var topScroll=document.getElementById("topScroll");window.onscroll=function(){scrollFunction()};function scrollFunction(){document.body.scrollTop>20||document.documentElement.scrollTop>20?topScroll.style.display="block":topScroll.style.display="none"}function topFunction(){document.body.scrollTop=0,document.documentElement.scrollTop=0}let stickySideBarElem=document.getElementById("stickySideBar"),stickyNavBar=!0;if(stickyNavBar){let e=document.getElementById("profileHeader"),t=e.offsetHeight+15;stickySideBarElem.style.top=t+"px"}else stickySideBarElem.style.top="50px"</script><script src=/js/readingTime.js></script></div><footer><div class="text-center pt-2"><span class=px-1><a href=https://github.com/BobbleLaw aria-label=github><svg width="2.7em" height="2.7em" viewBox="0 0 1792 1792"><path id="footer-socialNetworks-github-svg-path" d="M522 1352q-8 9-20-3-13-11-4-19 8-9 20 3 12 11 4 19zm-42-61q9 12 0 19-8 6-17-7t0-18q9-7 17 6zm-61-60q-5 7-13 2-10-5-7-12 3-5 13-2 10 5 7 12zm31 34q-6 7-16-3-9-11-2-16 6-6 16 3 9 11 2 16zm129 112q-4 12-19 6-17-4-13-15t19-7q16 5 13 16zm63 5q0 11-16 11-17 2-17-11 0-11 16-11 17-2 17 11zm58-10q2 10-14 14t-18-8 14-15q16-2 18 9zm964-956v960q0 119-84.5 203.5T1376 1664h-224q-16 0-24.5-1t-19.5-5-16-14.5-5-27.5v-239q0-97-52-142 57-6 102.5-18t94-39 81-66.5 53-105T1386 856q0-121-79-206 37-91-8-204-28-9-81 11t-92 44l-38 24q-93-26-192-26t-192 26q-16-11-42.5-27T578 459.5 492 446q-44 113-7 204-79 85-79 206 0 85 20.5 150t52.5 105 80.5 67 94 39 102.5 18q-40 36-49 103-21 10-45 15t-57 5-65.5-21.5T484 1274q-19-32-48.5-52t-49.5-24l-20-3q-21 0-29 4.5t-5 11.5 9 14 13 12l7 5q22 10 43.5 38t31.5 51l10 23q13 38 44 61.5t67 30 69.5 7 55.5-3.5l23-4q0 38 .5 103t.5 68q0 22-11 33.5t-22 13-33 1.5H416q-119 0-203.5-84.5T128 1376V416q0-119 84.5-203.5T416 128h960q119 0 203.5 84.5T1664 416z"/></svg>
</a></span><span class=px-1><a href=https://www.linkedin.com/in/boblzy aria-label=linkedin><svg width="2.4em" height="2.4em" fill="#fff" aria-label="LinkedIn" viewBox="0 0 512 512"><rect width="512" height="512" fill="#0077b5" rx="15%"/><circle cx="142" cy="138" r="37"/><path stroke="#fff" stroke-width="66" d="M244 194v198M142 194v198"/><path d="M276 282c0-20 13-40 36-40 24 0 33 18 33 45v105h66V279c0-61-32-89-76-89-34 0-51 19-59 32"/></svg></a></span></div><div class="container py-4"><div class="row justify-content-center"><div class="col-md-4 text-center"><div class=pb-2><a href=https://bobblelaw.github.io/ title="Bobble Law"><img alt="Footer logo" src=/logo.png height=40px width=40px></a></div>&copy; 2025 All rights reserved<div class=text-secondary>Made with
<span class=text-danger>&#10084;
</span>and
<a href=https://github.com/gurusabarish/hugo-profile target=_blank title="Designed and developed by gurusabarish">Hugo Profile</a></div></div></div></div></footer><script src=/bootstrap-5/js/bootstrap.bundle.min.js></script><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia&&window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))});var tooltipTriggerList=[].slice.call(document.querySelectorAll('[data-bs-toggle="tooltip"]')),tooltipList=tooltipTriggerList.map(function(e){return new bootstrap.Tooltip(e)})</script><script src=/js/search.js></script><section id=search-content class=py-2><div class=container id=search-results></div></section></body></html>