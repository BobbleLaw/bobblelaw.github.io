<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Bobble Law</title><link>/authors/host/</link><description>Recent content on Bobble Law</description><generator>Hugo -- gohugo.io</generator><language>en</language><copyright>&amp;copy; 2022 &lt;a href="#">Bobble Law&lt;/a> and &lt;a href="#">Stay Inc.&lt;/a></copyright><lastBuildDate>Thu, 27 Oct 2022 16:37:56 +0800</lastBuildDate><atom:link href="/authors/host/index.xml" rel="self" type="application/rss+xml"/><item><title>SLAM Interview FAQs</title><link>/posts/slam-interview-faq/</link><pubDate>Thu, 27 Oct 2022 16:37:56 +0800</pubDate><guid>/posts/slam-interview-faq/</guid><description>Linear Algebra 如何求解 $Ax=b$？SVD和QR分解哪个更快？ Depend on the rank of $[A | b]$.
Solution include QR decomposition, LTLD decomposition, Cholesky decomposition and SVD decomposition.
Optimization Basics Explain Gradient descent, Gaussian-Newton, LM, Dogleg Computer Vision Basics SIFT vs. SURF
Parallax and depth
$ \frac{parallax}{baseline} = \frac{focal~ length}{depth} $
Edge detection algorithms Filtering, augmentation, and detection. Gaussian filter and some handcrafted kernel to locate pixel gradient.
Canny Sobel Laplacian Hoffman transform 3D Basics 如何对匹配好的点做进一步的处理，已到达更好的效果？ Compare the distance with experienced threshold RANSAC KNN Explain RANSAC</description></item><item><title>Understanding Perspective-N-Points</title><link>/posts/understanding-pnp/</link><pubDate>Thu, 27 Oct 2022 16:37:56 +0800</pubDate><guid>/posts/understanding-pnp/</guid><description>Introduction The Perspective-n-Point (PnP) problem is the problem of estimating the relative pose between an object and the camera, given a set of correspondences between 3D points and their projections on the image plane. It is a fundamental problem that was first studied in the photogrammetry literature, and later on studied in the context of computer vision.
In this post, I will present a few solvers (among many), discuss their proofs and also show some concise implementations.</description></item><item><title>Moves in Returns</title><link>/posts/moves-in-return/</link><pubDate>Sat, 23 Oct 2021 02:00:00 +0000</pubDate><guid>/posts/moves-in-return/</guid><description>Today we&amp;rsquo;ll discuss code of the form:
T work(/* ... */) { /* ... */ return x; } This is a classical &amp;ldquo;return-by-value&amp;rdquo; and (wrongfully) associated with copies and overhead.
In many cases, this will actually move the result instead of copying it. For modern C++, one could even argue that this will move in most cases (or, as we will see, completely elide the copy and directly construct in the result memory).
This post discusses several common patterns and if they are moved, copies, or elided.</description></item><item><title>Optimization without Inlining</title><link>/posts/inline-optimization/</link><pubDate>Sun, 17 Oct 2021 02:00:00 +0000</pubDate><guid>/posts/inline-optimization/</guid><description>Inlining is one of the most important compiler optimizations. We can often write abstractions and thin wrapper functions without incurring any performance penalty, because the compiler will expand the method for us at call site.
If a function is not inlined, conventional wisdom says that the compiler has to assume that the method can modify any global state and change the memory behind any pointer or reference that might have &amp;ldquo;escaped&amp;rdquo;.
In this short post, I&amp;rsquo;ll demonstrate exactly this effect.</description></item><item><title>std::unordered_map Performance and Usage</title><link>/posts/unordered-map-usage-and-performance/</link><pubDate>Mon, 03 May 2021 00:00:00 +0000</pubDate><guid>/posts/unordered-map-usage-and-performance/</guid><description>Origin Story We have always been told that hashmap is the best associative container that offer O(1) insert, delete, and lookup. However, the customization space of it is quite large and depending on the use case, the trade-off space can change radically. std::unordered_map is (in)famous for having an API that basically forces implementers to use &amp;ldquo;buckets with linked lists&amp;rdquo;, also known as separate chaining. Many performance-critical applications swear on open addressing, often storing keys and values directly in arrays (either together or separate).</description></item><item><title>std::sort multiple ranges</title><link>/posts/sort-multiple-range/</link><pubDate>Sat, 28 Nov 2020 02:00:00 +0000</pubDate><guid>/posts/sort-multiple-range/</guid><description>std::sort is a great utility. You can easily sort subranges and provide custom comparison functions. However, it struggles with the following scenario:
std::vector&amp;lt;int&amp;gt; keys = ...; std::vector&amp;lt;std::string&amp;gt; values = ...; std::sort(...); // ??? We want to sort by keys but keep the 1-on-1 correspondence with values, i.e. keep the ranges &amp;ldquo;in sync&amp;rdquo; during sorting. A common solution is to allocate a vector of indices, sort these indices, and then apply the resulting permutation. However, the need for an additional allocation and bad cache locality due to indirection make this a suboptimal solution.</description></item><item><title>How MSCKF Works? -- Preliminaries</title><link>/posts/how-msckf-works-preliminaries/</link><pubDate>Fri, 20 Nov 2020 22:52:56 +0800</pubDate><guid>/posts/how-msckf-works-preliminaries/</guid><description>Notations Review of Extended Kalman Filter \[\begin{align} x_{k} &amp;= f(x_{k-1}, u_{k-1}) + w_{k-1} \\ z_{k} &amp;= h(x_{k}) + v_{k-1} \end{align}\] where $w_{k} ∼ N(0, Q_{k})$, $v_{k} ∼ N(0, R_{k})$.
\[\begin{align} _{G}^{B}\.{q}(t) &amp;= \frac{1}{2} Ω(^{G}ω(t))_{G}^{B}q(t), ~ with ~ Ω(ω)= \begin{bmatrix} -[ω]_{×} &amp; ω \\ -ω^{T} &amp; 0 \end{bmatrix} \\ ^{G}\.{p}(t) &amp;= ~ ^{G}v(t) \\ ^{G}\.{v}(t) &amp;= ~ ^{G}a(t) \\ \.{b}_{g}(t) &amp;= n_{w_{g}}(t) \\ \.{b}_{a}(t) &amp;= n_{w_{a}}(t) \end{align}\] \[\begin{align} _{G}^{B}\.{q}(t) &amp;= \frac{1}{2} Ω(^{G}ω(t))_{G}^{B}q(t), ~ with ~ Ω(ω)= \begin{bmatrix} -[ω]_{×} &amp; ω \\ -ω^{T} &amp; 0 \end{bmatrix} \\ ^{G}\.</description></item><item><title>How MSCKF Works? -- Theories</title><link>/posts/how-msckf-works-theories/</link><pubDate>Fri, 20 Nov 2020 22:52:56 +0800</pubDate><guid>/posts/how-msckf-works-theories/</guid><description/></item><item><title>How ORB-SLAM Works? -- Preliminaries</title><link>/posts/how-orbslam-works-preliminaries/</link><pubDate>Fri, 20 Nov 2020 22:52:56 +0800</pubDate><guid>/posts/how-orbslam-works-preliminaries/</guid><description/></item><item><title>How to Become a Video Game Designer?</title><link>/posts/how-to-become-a-video-game-designer/</link><pubDate>Fri, 20 Nov 2020 22:52:56 +0800</pubDate><guid>/posts/how-to-become-a-video-game-designer/</guid><description>This is some notes that I used for preparing the Game Designer position in Tencent.
You will read about
Career path Education Work experience Game Design vs. Game Development First of all, we need to talk about the difference between game design and game development.
These two are sometimes interchangeable but distinct.
Game Designer needs to know
game concept mechanics storyline while Game developer tends to know
animation engine programming Here are some websites you defintely should take a look to learn how to become a good game designer.</description></item><item><title>How to use CMake to configure a Qt project?</title><link>/posts/how-to-use-cmake-to-configure-a-qt-project/</link><pubDate>Fri, 20 Nov 2020 22:52:56 +0800</pubDate><guid>/posts/how-to-use-cmake-to-configure-a-qt-project/</guid><description>A Simple Qt code Here is a hello world code for Qt
#include &amp;lt;QtCore/QCoreApplication&amp;gt; #include &amp;lt;QtCore/QDebug&amp;gt; int main(int argc, char** argv){ QCoreApplication app(argc, argv); qDebug() &amp;lt;&amp;lt; &amp;quot;Hello, Qt!&amp;quot;; app.exec() } If we don&amp;rsquo;t use IDE or qmake, but compiler, this is the command g++ main.cpp -I\\path\to\Qt\5.13.0\include -o main -L\path\to\Qt\5.13.0\lib -lQtCore4 If we have qmake, all we need is CONFIG +=qt QT -= gui SOURCE += main.cpp If we use cmake, our old friend CMakeList.txt comes to stage PROJECT(example) FIND_PACKAGE(Qt4 COMPONENTS QtCore REQUIRED) INCLUDE(${QT_USE_FILE}) ADD_EXECUTABLE(example main.</description></item><item><title>How VINS Works? -- Code</title><link>/posts/how-vins-works-code/</link><pubDate>Fri, 20 Nov 2020 22:52:56 +0800</pubDate><guid>/posts/how-vins-works-code/</guid><description/></item><item><title>How VINS works? -- Preliminaries</title><link>/posts/how-vins-works-preliminaries/</link><pubDate>Fri, 20 Nov 2020 22:52:56 +0800</pubDate><guid>/posts/how-vins-works-preliminaries/</guid><description>&lt;div>
&lt;div>
&lt;p>Eureka supports the rendering of mathematical formulas by using KaTeX.&lt;/p></description></item><item><title>How VINS works? -- Theories</title><link>/posts/how-vins-works-theories/</link><pubDate>Fri, 20 Nov 2020 22:52:56 +0800</pubDate><guid>/posts/how-vins-works-theories/</guid><description>\[\begin{align} _{G}^{B}\.{q}(t) &amp;= \frac{1}{2} Ω(^{G}ω(t))_{G}^{B}q(t), ~ with ~ Ω(ω)= \begin{bmatrix} -[ω]_{×} &amp; ω \\ -ω^{T} &amp; 0 \end{bmatrix} \\ ^{G}\.{p}(t) &amp;= ~ ^{G}v(t) \\ ^{G}\.{v}(t) &amp;= ~ ^{G}a(t) \\ \.{b}_{g}(t) &amp;= n_{w_{g}}(t) \\ \.{b}_{a}(t) &amp;= n_{w_{a}}(t) \end{align}\] \[ \int u \frac{dv}{dx}\, dx=uv-\int \frac{du}{dx}v\,dx \] \[ p(\boldsymbol{x} | \boldsymbol{z}) = p(\boldsymbol{z} | \boldsymbol{x})p(\boldsymbol{x}) \] \[ p(\boldsymbol{z} | \boldsymbol{x}) = \prod_{i} p(\boldsymbol{z_i} | \boldsymbol{x_i}) \] For example,
\[\begin{align} \~a_t &amp;= a_t + ~ _w^T{R} ~ ^w{g} + b_{a_t} + n_a \\ \~\omega &amp;= \omega_t + b_{\omega_t} + n_\omega \end{align}\] \[ n_a \sim N(0, \sigma_a^2) \\ n_{\omega} \sim N(0, \sigma_{\omega}^2) \] \[\begin{align} _{B_{k+1}}^G{p} &amp;=~ _{B_{k}}^G{p} +~ _{B_{k}}^G{v}\varDelta{t} + \iint_{[t_k, t_{k+1}]} a_t ~ dt^2 \\ _{B_{k+1}}^G{v} &amp;=~ _{B_{k}}^G{v} + \int_{[t_k, t_{k+1}]} a_t ~ dt \\ _{B_{k+1}}^G{q} &amp;=~ _{B_{k}}^G{q} \otimes \int_{[t_k, t_{k+1}]} \frac{1}{2} ~ ^{B_{k}}{q} \otimes \begin{bmatrix} \omega_t \\ 0 \end{bmatrix} dt \end{align}\] \[\begin{align} _G^{B_k}{R} ~ _{B_{k+1}}^G{p} &amp;=~ _{B_{k}}^G{p} +~ _{B_{k}}^G{v}\varDelta{t} + \iint_{[t_k, t_{k+1}]} a_t ~ dt^2 \\ _G^{B_k}{R} ~ _{B_{k+1}}^G{v} &amp;=~ _{B_{k}}^G{v} + \int_{[t_k, t_{k+1}]} a_t ~ dt \\ _G^{B_k}{q} \otimes _{B_{k+1}}^G{q} &amp;=~ \gamma_{B_{k+1}}^{B_k} \end{align}\] \[\begin{align} \alpha_{B_{k+1}}^{B_k} &amp;= \iint_{[t_k, t_{k+1}]} {_{B_t}^{B_k}{R}(\^a_t-b_{a_t}-n_a)} ~ dt^2 \\ \beta_{B_{k+1}}^{B_k} &amp;= \int_{[t_k, t_{k+1}]} {_{B_t}^{B_k}{R}(\^a_t-b_{a_t}-n_a)} ~ dt \\ \gamma_{B_{k+1}}^{B_k} &amp;= \int_{[t_k, t_{k+1}]} {\frac{1}{2}\Omega(\~\omega_t - b_{\omega_t} - n_\omega)\gamma_{B_t}^{B_{k+1}}} dt \end{align}\] \[\begin{align} \alpha_{B_{k+1}}^{B_k} &amp;\approx \^\alpha_{B_{k+1}}^{B_k} + J_{b_a}^\alpha\delta{b_a} + J_{b_a}^\alpha\delta{b_\omega}\\ \beta_{B_{k+1}}^{B_k} &amp;\approx \^\beta_{B_{k+1}}^{B_k} + J_{b_a}^\beta\delta{b_a} + J_{b_a}^\beta\delta{b_\omega}\\ \gamma_{B_{k+1}}^{B_k} &amp;\approx \^\gamma_{B_{k+1}}^{B_k} \otimes \begin{bmatrix} 1 \\ \frac{1}{2}J_{b_\omega}^\gamma\delta{b_\omega} \end{bmatrix} \end{align}\] Question: Purpose of pre-integration?</description></item><item><title>Notes on Linux Development</title><link>/posts/notes-on-linux-dev/</link><pubDate>Fri, 20 Nov 2020 22:52:56 +0800</pubDate><guid>/posts/notes-on-linux-dev/</guid><description>How to use previous version of gcc This problem arises when we try to compile mex file in Matlab. It shows a warning as
Warning: You are using gcc version '7.x.x'. The version of gcc is not supported. The version currently supported with MEX is '6.4.x'. For a list of currently supported compilers see An easy solution is to do as followed (simply install the target version),
sudo apt-get update &amp;amp;&amp;amp; \ sudo apt-get install build-essential software-properties-common -y &amp;amp;&amp;amp; \ sudo add-apt-repository ppa:ubuntu-toolchain-r/test -y &amp;amp;&amp;amp; \ sudo apt-get update &amp;amp;&amp;amp; \ sudo apt-get install gcc-6 g++-6 -y &amp;amp;&amp;amp; \ sudo update-alternatives --install /usr/bin/gcc gcc /usr/bin/gcc-6 60 --slave /usr/bin/g++ g++ /usr/bin/g++-6 &amp;amp;&amp;amp; \ gcc -v But this will affect the global gcc/g++, so we change the configure file for mex only,</description></item><item><title>Understanding Automatic Differentiation</title><link>/posts/understanding-automatic-differentiation/</link><pubDate>Fri, 20 Nov 2020 22:52:56 +0800</pubDate><guid>/posts/understanding-automatic-differentiation/</guid><description>Deriving derivatives is not fun. In this post, I will deep dive into the methods for automatic differentiation (AD). After reading this post, I hope you can feel confident with using the various AD techniques, and hopefully never manually calculate derivatives again. Note that this post is not a comparison between AD libraries. For that, a good starting point is here.
Why Automatic Differentiation? Automatic differentiation is a natural continuation of scientists and engineers’ pursuit for mechanizing computation.</description></item><item><title>Multi-Level Break in C++ via IIFE</title><link>/posts/multi-level-break/</link><pubDate>Wed, 28 Oct 2020 02:00:00 +0000</pubDate><guid>/posts/multi-level-break/</guid><description>I guess we all have been at this point.
for (auto i : ...) for (auto j : ...) if (condition(i, j)) { break outer??? } You want to search something, and for one reason or another you end up with a nested loop. You find what you searched for and now want to break all the way to the outer loop.
If only we had multi-level breaks.
But we don&amp;rsquo;t.
So people introduce flags:</description></item><item><title>range_ref&lt;T></title><link>/posts/range-ref/</link><pubDate>Sat, 24 Oct 2020 02:00:00 +0000</pubDate><guid>/posts/range-ref/</guid><description>Passing references to functions is great.
struct some_user_type; void foo(some_user_type const&amp;amp; v) { // freely read from v } Memory management and lifetime handling is done by the caller. Users of your function / API have a liberating amount of freedom how they organize their data: on the stack, on the heap, in smart pointers, in vectors, it doesn&amp;rsquo;t matter. They can pass a reference to your function. No (potentially expensive) copy is performed.
From an API perspective, C++ references are views on a single object.</description></item><item><title>Recursive Lambdas in C++</title><link>/posts/recursive-lambda-function/</link><pubDate>Sat, 12 Sep 2020 02:00:00 +0000</pubDate><guid>/posts/recursive-lambda-function/</guid><description>auto fib = [](int n) { if (n &amp;lt;= 1) return n; return fib(n - 1) + fib(n - 2); }; auto i = fib(7); If only it were that simple.
Obviously, any performance-conscious programmer will compute Fibonacci numbers iteratively (or even explicitly), but this solution will serve as an example for an underappreciated tool: recursive lambdas.
Lambdas are one of my favorite features in any programming language and while I long for a shorter syntax in C++, I still use them quite ubiquitously, especially for local functions.</description></item></channel></rss>