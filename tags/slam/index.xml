<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>SLAM on Bobble Law</title><link>/tags/slam/</link><description>Recent content in SLAM on Bobble Law</description><generator>Hugo -- gohugo.io</generator><language>en</language><copyright>&amp;copy; 2022 &lt;a href="#">Bobble Law&lt;/a> and &lt;a href="#">Stay Inc.&lt;/a></copyright><lastBuildDate>Thu, 27 Oct 2022 16:37:56 +0800</lastBuildDate><atom:link href="/tags/slam/index.xml" rel="self" type="application/rss+xml"/><item><title>SLAM Interview FAQs</title><link>/posts/slam-interview-faq/</link><pubDate>Thu, 27 Oct 2022 16:37:56 +0800</pubDate><guid>/posts/slam-interview-faq/</guid><description>Linear Algebra 如何求解 $Ax=b$？SVD和QR分解哪个更快？ Depend on the rank of $[A | b]$.
Solution include QR decomposition, LTLD decomposition, Cholesky decomposition and SVD decomposition.
Optimization Basics Explain Gradient descent, Gaussian-Newton, LM, Dogleg Computer Vision Basics SIFT vs. SURF
Parallax and depth
$ \frac{parallax}{baseline} = \frac{focal~ length}{depth} $
Edge detection algorithms Filtering, augmentation, and detection. Gaussian filter and some handcrafted kernel to locate pixel gradient.
Canny Sobel Laplacian Hoffman transform 3D Basics 如何对匹配好的点做进一步的处理，已到达更好的效果？ Compare the distance with experienced threshold RANSAC KNN Explain RANSAC</description></item><item><title>How MSCKF Works? -- Preliminaries</title><link>/posts/how-msckf-works-preliminaries/</link><pubDate>Fri, 20 Nov 2020 22:52:56 +0800</pubDate><guid>/posts/how-msckf-works-preliminaries/</guid><description>Notations Review of Extended Kalman Filter \[\begin{align} x_{k} &amp;= f(x_{k-1}, u_{k-1}) + w_{k-1} \\ z_{k} &amp;= h(x_{k}) + v_{k-1} \end{align}\] where $w_{k} ∼ N(0, Q_{k})$, $v_{k} ∼ N(0, R_{k})$.
\[\begin{align} _{G}^{B}\.{q}(t) &amp;= \frac{1}{2} Ω(^{G}ω(t))_{G}^{B}q(t), ~ with ~ Ω(ω)= \begin{bmatrix} -[ω]_{×} &amp; ω \\ -ω^{T} &amp; 0 \end{bmatrix} \\ ^{G}\.{p}(t) &amp;= ~ ^{G}v(t) \\ ^{G}\.{v}(t) &amp;= ~ ^{G}a(t) \\ \.{b}_{g}(t) &amp;= n_{w_{g}}(t) \\ \.{b}_{a}(t) &amp;= n_{w_{a}}(t) \end{align}\] \[\begin{align} _{G}^{B}\.{q}(t) &amp;= \frac{1}{2} Ω(^{G}ω(t))_{G}^{B}q(t), ~ with ~ Ω(ω)= \begin{bmatrix} -[ω]_{×} &amp; ω \\ -ω^{T} &amp; 0 \end{bmatrix} \\ ^{G}\.</description></item><item><title>How MSCKF Works? -- Theories</title><link>/posts/how-msckf-works-theories/</link><pubDate>Fri, 20 Nov 2020 22:52:56 +0800</pubDate><guid>/posts/how-msckf-works-theories/</guid><description/></item><item><title>How ORB-SLAM Works? -- Preliminaries</title><link>/posts/how-orbslam-works-preliminaries/</link><pubDate>Fri, 20 Nov 2020 22:52:56 +0800</pubDate><guid>/posts/how-orbslam-works-preliminaries/</guid><description/></item><item><title>How VINS Works? -- Code</title><link>/posts/how-vins-works-code/</link><pubDate>Fri, 20 Nov 2020 22:52:56 +0800</pubDate><guid>/posts/how-vins-works-code/</guid><description/></item><item><title>How VINS works? -- Preliminaries</title><link>/posts/how-vins-works-preliminaries/</link><pubDate>Fri, 20 Nov 2020 22:52:56 +0800</pubDate><guid>/posts/how-vins-works-preliminaries/</guid><description>&lt;div>
&lt;div>
&lt;p>Eureka supports the rendering of mathematical formulas by using KaTeX.&lt;/p></description></item><item><title>How VINS works? -- Theories</title><link>/posts/how-vins-works-theories/</link><pubDate>Fri, 20 Nov 2020 22:52:56 +0800</pubDate><guid>/posts/how-vins-works-theories/</guid><description>\[\begin{align} _{G}^{B}\.{q}(t) &amp;= \frac{1}{2} Ω(^{G}ω(t))_{G}^{B}q(t), ~ with ~ Ω(ω)= \begin{bmatrix} -[ω]_{×} &amp; ω \\ -ω^{T} &amp; 0 \end{bmatrix} \\ ^{G}\.{p}(t) &amp;= ~ ^{G}v(t) \\ ^{G}\.{v}(t) &amp;= ~ ^{G}a(t) \\ \.{b}_{g}(t) &amp;= n_{w_{g}}(t) \\ \.{b}_{a}(t) &amp;= n_{w_{a}}(t) \end{align}\] \[ \int u \frac{dv}{dx}\, dx=uv-\int \frac{du}{dx}v\,dx \] \[ p(\boldsymbol{x} | \boldsymbol{z}) = p(\boldsymbol{z} | \boldsymbol{x})p(\boldsymbol{x}) \] \[ p(\boldsymbol{z} | \boldsymbol{x}) = \prod_{i} p(\boldsymbol{z_i} | \boldsymbol{x_i}) \] For example,
\[\begin{align} \~a_t &amp;= a_t + ~ _w^T{R} ~ ^w{g} + b_{a_t} + n_a \\ \~\omega &amp;= \omega_t + b_{\omega_t} + n_\omega \end{align}\] \[ n_a \sim N(0, \sigma_a^2) \\ n_{\omega} \sim N(0, \sigma_{\omega}^2) \] \[\begin{align} _{B_{k+1}}^G{p} &amp;=~ _{B_{k}}^G{p} +~ _{B_{k}}^G{v}\varDelta{t} + \iint_{[t_k, t_{k+1}]} a_t ~ dt^2 \\ _{B_{k+1}}^G{v} &amp;=~ _{B_{k}}^G{v} + \int_{[t_k, t_{k+1}]} a_t ~ dt \\ _{B_{k+1}}^G{q} &amp;=~ _{B_{k}}^G{q} \otimes \int_{[t_k, t_{k+1}]} \frac{1}{2} ~ ^{B_{k}}{q} \otimes \begin{bmatrix} \omega_t \\ 0 \end{bmatrix} dt \end{align}\] \[\begin{align} _G^{B_k}{R} ~ _{B_{k+1}}^G{p} &amp;=~ _{B_{k}}^G{p} +~ _{B_{k}}^G{v}\varDelta{t} + \iint_{[t_k, t_{k+1}]} a_t ~ dt^2 \\ _G^{B_k}{R} ~ _{B_{k+1}}^G{v} &amp;=~ _{B_{k}}^G{v} + \int_{[t_k, t_{k+1}]} a_t ~ dt \\ _G^{B_k}{q} \otimes _{B_{k+1}}^G{q} &amp;=~ \gamma_{B_{k+1}}^{B_k} \end{align}\] \[\begin{align} \alpha_{B_{k+1}}^{B_k} &amp;= \iint_{[t_k, t_{k+1}]} {_{B_t}^{B_k}{R}(\^a_t-b_{a_t}-n_a)} ~ dt^2 \\ \beta_{B_{k+1}}^{B_k} &amp;= \int_{[t_k, t_{k+1}]} {_{B_t}^{B_k}{R}(\^a_t-b_{a_t}-n_a)} ~ dt \\ \gamma_{B_{k+1}}^{B_k} &amp;= \int_{[t_k, t_{k+1}]} {\frac{1}{2}\Omega(\~\omega_t - b_{\omega_t} - n_\omega)\gamma_{B_t}^{B_{k+1}}} dt \end{align}\] \[\begin{align} \alpha_{B_{k+1}}^{B_k} &amp;\approx \^\alpha_{B_{k+1}}^{B_k} + J_{b_a}^\alpha\delta{b_a} + J_{b_a}^\alpha\delta{b_\omega}\\ \beta_{B_{k+1}}^{B_k} &amp;\approx \^\beta_{B_{k+1}}^{B_k} + J_{b_a}^\beta\delta{b_a} + J_{b_a}^\beta\delta{b_\omega}\\ \gamma_{B_{k+1}}^{B_k} &amp;\approx \^\gamma_{B_{k+1}}^{B_k} \otimes \begin{bmatrix} 1 \\ \frac{1}{2}J_{b_\omega}^\gamma\delta{b_\omega} \end{bmatrix} \end{align}\] Question: Purpose of pre-integration?</description></item></channel></rss>