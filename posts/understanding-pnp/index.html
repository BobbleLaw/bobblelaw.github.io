<!doctype html><html lang=en dir=ltr class=dark><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><title>Understanding Perspective-N-Points | Bobble Law</title><meta name=generator content="Hugo Eureka 0.9.3"><link rel=stylesheet href=https://bobblelaw.github.io/css/eureka.min.9cec6350e37e534b0338fa9a085bf06855de3b0f2dcf857e792e5e97b07ea905d4d5513db554cbc26a9c3da622bae92d.css><script defer src=https://bobblelaw.github.io/js/eureka.min.fa9a6bf6d7a50bb635b4cca7d2ba5cf3dfb095ae3798773f1328f7950028b48c17d06276594e1b5f244a25a6c969a705.js></script>
<link rel=preconnect href=https://fonts.googleapis.com><link rel=preconnect href=https://fonts.gstatic.com crossorigin><link rel=preload href="https://fonts.googleapis.com/css2?family=Lora:wght@400;600;700&family=Noto+Serif+SC:wght@400;600;700&display=swap" as=style onload='this.onload=null,this.rel="stylesheet"'><link rel=stylesheet href=https://cdn.jsdelivr.net/gh/highlightjs/cdn-release@11.4.0/build/styles/base16/solarized-light.min.css media=print onload='this.media="all",this.onload=null' crossorigin><script defer src=https://cdn.jsdelivr.net/gh/highlightjs/cdn-release@11.4.0/build/highlight.min.js crossorigin></script>
<script defer src=https://cdn.jsdelivr.net/gh/highlightjs/cdn-release@11.4.0/build/languages/cpp,%20swift,%20python.min.js crossorigin></script>
<link rel=stylesheet href=https://bobblelaw.github.io/css/highlightjs.min.2958991528e43eb6fc9b8c4f2b8e052f79c4010718e1d1e888a777620e9ee63021c2c57ec7417a3108019bb8c41943e6.css media=print onload='this.media="all",this.onload=null'><script defer type=text/javascript src=https://bobblelaw.github.io/js/fontawesome.min.a975d08212c5439f29e6074e7ad58e159ae1ef5efb6a31962fa3b6885557e794dd9315f4a8a16d705066d023f4eaaf07.js></script>
<link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.15.2/dist/katex.min.css integrity=sha384-MlJdn/WNKDGXveldHDdyRP1R4CTHr3FeuDNfhsLPYrq2t0UBkUdK2jyTnXPEK1NQ media=print onload='this.media="all",this.onload=null' crossorigin><script defer src=https://cdn.jsdelivr.net/npm/katex@0.15.2/dist/katex.min.js integrity=sha384-VQ8d8WVFw0yHhCk5E8I86oOhv48xLpnDZx5T9GogA/Y84DcCKWXDmSDfn13bzFZY crossorigin></script>
<script defer src=https://cdn.jsdelivr.net/npm/katex@0.15.2/dist/contrib/auto-render.min.js integrity=sha384-+XBljXPPiv+OzfbB3cVmLHf4hdUFHlWNZN5spNQ7rmHTXpd7WvJum6fIACpNNfIR crossorigin></script>
<script>document.addEventListener("DOMContentLoaded",function(){renderMathInElement(document.body,{delimiters:[{left:"$$",right:"$$",display:!0},{left:"$",right:"$",display:!1},{left:"\\(",right:"\\)",display:!1},{left:"\\[",right:"\\]",display:!0}]})})</script><script defer src=https://cdn.jsdelivr.net/npm/mermaid@8.14.0/dist/mermaid.min.js integrity=sha384-atOyb0FxAgN9LyAc6PEf9BjgwLISyansgdH8/VXQH8p2o5vfrRgmGIJ2Sg22L0A0 crossorigin></script>
<link rel=icon type=image/png sizes=32x32 href=https://bobblelaw.github.io/images/icon_hucb7ee3c6385b6f166198d69440e1110c_52330_32x32_fill_box_center_3.png><link rel=apple-touch-icon sizes=180x180 href=https://bobblelaw.github.io/images/icon_hucb7ee3c6385b6f166198d69440e1110c_52330_180x180_fill_box_center_3.png><meta name=description content="Introduction The Perspective-n-Point (PnP) problem is the problem of estimating the relative pose between an object and the camera, given a set of correspondences between 3D points and their projections on the image plane. It is a fundamental problem that was first studied in the photogrammetry literature, and later on studied in the context of computer vision.
In this post, I will present a few solvers (among many), discuss their proofs and also show some concise implementations."><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"https://bobblelaw.github.io/posts/"},{"@type":"ListItem","position":2,"name":"Understanding Perspective-N-Points","item":"https://bobblelaw.github.io/posts/understanding-pnp/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"Article","mainEntityOfPage":{"@type":"WebPage","@id":"https://bobblelaw.github.io/posts/understanding-pnp/"},"headline":"Understanding Perspective-N-Points | Bobble Law","datePublished":"2021-04-18T15:17:26+08:00","dateModified":"2022-11-20T22:52:56+08:00","wordCount":385,"author":{"@type":"Person","name":["host"]},"publisher":{"@type":"Person","name":"Bob Law","logo":{"@type":"ImageObject","url":"https://bobblelaw.github.io/images/icon.png"}},"description":"Introduction The Perspective-n-Point (PnP) problem is the problem of estimating the relative pose between an object and the camera, given a set of correspondences between 3D points and their projections on the image plane. It is a fundamental problem that was first studied in the photogrammetry literature, and later on studied in the context of computer vision.\nIn this post, I will present a few solvers (among many), discuss their proofs and also show some concise implementations."}</script><meta property="og:title" content="Understanding Perspective-N-Points | Bobble Law"><meta property="og:type" content="article"><meta property="og:image" content="https://bobblelaw.github.io/images/icon.png"><meta property="og:url" content="https://bobblelaw.github.io/posts/understanding-pnp/"><meta property="og:description" content="Introduction The Perspective-n-Point (PnP) problem is the problem of estimating the relative pose between an object and the camera, given a set of correspondences between 3D points and their projections on the image plane. It is a fundamental problem that was first studied in the photogrammetry literature, and later on studied in the context of computer vision.
In this post, I will present a few solvers (among many), discuss their proofs and also show some concise implementations."><meta property="og:locale" content="en"><meta property="og:site_name" content="Bobble Law"><meta property="article:published_time" content="2021-04-18T15:17:26+08:00"><meta property="article:modified_time" content="2022-11-20T22:52:56+08:00"><meta property="article:section" content="posts"><meta property="article:tag" content="registration"><body class="flex min-h-screen flex-col"><header class="min-h-16 pl-scrollbar bg-secondary-bg fixed z-50 flex w-full items-center shadow-sm"><div class="mx-auto w-full max-w-screen-xl"><script>let storageColorScheme=localStorage.getItem("lightDarkMode");(storageColorScheme=="Auto"&&window.matchMedia("(prefers-color-scheme: light)").matches||storageColorScheme=="Light")&&document.getElementsByTagName("html")[0].classList.remove("dark")</script><nav class="flex items-center justify-between flex-wrap px-4 py-4 md:py-0"><a href=/ class="me-6 text-primary-text text-xl font-bold">Bobble Law</a>
<button id=navbar-btn class="md:hidden flex items-center px-3 py-2" aria-label="Open Navbar">
<i class="fas fa-bars"></i></button><div id=target class="hidden block md:flex md:grow md:justify-between md:items-center w-full md:w-auto text-primary-text z-20"><div class="md:flex md:h-16 text-sm md:grow pb-4 md:pb-0 border-b md:border-b-0"><a href=/#about class="block mt-4 md:inline-block md:mt-0 md:h-(16-4px) md:leading-(16-4px) box-border md:border-t-2 md:border-b-2 border-transparent me-4">About</a>
<a href=/posts/ class="block mt-4 md:inline-block md:mt-0 md:h-(16-4px) md:leading-(16-4px) box-border md:border-t-2 md:border-b-2 selected-menu-item me-4">Posts</a>
<a href=/docs/ class="block mt-4 md:inline-block md:mt-0 md:h-(16-4px) md:leading-(16-4px) box-border md:border-t-2 md:border-b-2 border-transparent me-4">Topics</a></div><div class=flex><div class="relative pt-4 md:pt-0"><div class="cursor-pointer hover:text-eureka" id=lightDarkMode><i class="fas fa-moon"></i></div><div class="fixed hidden inset-0 opacity-0 h-full w-full cursor-default z-30" id=is-open></div><div class="absolute flex flex-col start-0 md:start-auto end-auto md:end-0 hidden bg-secondary-bg w-48 rounded py-2 border border-tertiary-bg cursor-pointer z-40" id=lightDarkOptions><span class="px-4 py-1 hover:text-eureka" name=Light>Light</span>
<span class="px-4 py-1 hover:text-eureka" name=Dark>Dark</span>
<span class="px-4 py-1 hover:text-eureka" name=Auto>Auto</span></div></div></div></div><div class="fixed hidden inset-0 opacity-0 h-full w-full cursor-default z-0" id=is-open-mobile></div></nav><script>let element=document.getElementById("lightDarkMode");storageColorScheme=="Auto"?(element.firstElementChild.classList.remove("fa-moon"),element.firstElementChild.setAttribute("data-icon","adjust"),element.firstElementChild.classList.add("fa-adjust"),document.addEventListener("DOMContentLoaded",()=>{window.matchMedia("(prefers-color-scheme: dark)").addEventListener("change",switchDarkMode)})):storageColorScheme=="Light"&&(element.firstElementChild.classList.remove("fa-moon"),element.firstElementChild.setAttribute("data-icon","sun"),element.firstElementChild.classList.add("fa-sun")),document.addEventListener("DOMContentLoaded",()=>{getcolorscheme(),switchBurger()})</script></div></header><main class="grow pt-16"><div class=pl-scrollbar><div class="mx-auto w-full max-w-screen-xl lg:px-4 xl:px-8"><div class="grid grid-cols-2 gap-4 lg:grid-cols-8 lg:pt-12"><div class="lg:col-start-2 bg-secondary-bg col-span-2 rounded px-6 py-8 lg:col-span-6"><article class=prose><h1 class=mb-4>Understanding Perspective-N-Points</h1><div class="text-tertiary-text not-prose mt-2 flex flex-row flex-wrap items-center"><div class="me-6 my-2"><i class="fas fa-calendar me-1"></i>
<span>2021-04-18</span></div><div class="me-6 my-2"><i class="fas fa-clock me-1"></i>
<span>2 min read</span></div></div><h2 id=introduction>Introduction</h2><p>The Perspective-n-Point (PnP) problem is the problem of estimating the relative pose between an object and the camera, given a set of correspondences between 3D points and their projections on the image plane.
It is a fundamental problem that was first studied in the photogrammetry literature, and later on studied in the context of computer vision.</p><p>In this post, I will present a few solvers (among many), discuss their proofs and also show some concise implementations.
I will focus on the minimal solvers - solutions to the PnP problem that requires the minimal amount of information.
In this case, we need at least three pairs of correspondences, and the minimal solvers that only require three pairs of correspondences are called P3P solvers.</p><h2 id=preliminaries>Preliminaries</h2><p>So, what is a PnP problem exactly?
To understand this, let&rsquo;s first look at the P3P problem.
Fig. 1 shows the typical geometry of a P3P problem instance.
$P_{1}$, $P_{2}$ and $P_{3}$ are three known 3D points in the fixed world frame, and $P_{1}^{I}$, $P_{2}^{I}$ and $P_{3}^{I}$ are their projections on the image plane respectively.
$O$ is the camera&rsquo;s optical center, also known as the center of projection.
Note that we assume a calibrated pinhole camera: that is we know the camera&rsquo;s focal lengths and distortion coefficients,
and the image points $P_{1}^{I}$, $P_{2}^{I}$ and $P_{3}^{I}$ are calibrated rays with two degrees of freedom each.</p><p>The goal of the P3P problem is: find the $P_{1}$, $P_{2}$ and $P_{3}$’s coordinates in the camera frame.
And PnP problems are the extended version: find $P_{i}$, $i = {1 \ldots n}$&rsquo;s coordinates in the camera frame.
To put it in a more algebraic form, we have the following equation:</p><div>\[\begin{aligned}
P^{C}_{i} = R^{C}_{W} P_{i} + t^{C} \qquad i = {1 \ldots 3}
\end{aligned}\]<div><div>\[\begin{aligned}
x ={}& a+b+c+{} \\
&d+e+f+g
\end{aligned}\]</div><p>where $R^{C}$ and $t^{C}$ are the relative transformation we are trying to solve (so that we can recover $P^{C}<em>{i}$, the positions of the points in the camera’s frame).
We know the projections of $P</em>{i}$ on the camera’s pixel space.</p><p>Interestingly, the early solutions to this problem solve for $P^{C}_{i}$ directly, then find the $R^{C}$ and $t^{C}$ using <a href=arun_method_for_3d_reg.html>Arun&rsquo;s Method.</a>
For them, the problem of P3P boils down to solving the geometry of a tetrahedron.
The first three methods introduced in this pose belong to this category.</p></article><div class=my-4><a href=https://bobblelaw.github.io/tags/registration/ class="inline-block bg-tertiary-bg text-sm rounded px-3 py-1 my-1 me-2 hover:text-eureka">#registration</a></div><div class=py-2><div class="my-8 flex flex-col items-center md:flex-row"><a href=https://bobblelaw.github.io/authors/host/ class="md:me-4 text-primary-text h-24 w-24"><img src=https://bobblelaw.github.io/images/cartoon_me.png class="bg-primary-bg w-full rounded-full" alt=Avatar></a><div class="mt-4 w-full md:mt-0 md:w-auto"><a href=https://bobblelaw.github.io/authors/host/ class="mb-2 block border-b pb-1 text-lg font-bold"><h3>Lo, Tszwan</h3></a><span class="block pb-2"></span>
<a href=mailto:bobble2579@hotmail.com class=me-2><i class="fas fa-envelope"></i></a>
<a href=https://github.com/BobbleLaw class=me-2><i class="fab fa-github"></i></a></div></div></div><div class="-mx-2 mt-4 flex flex-col border-t px-2 pt-4 md:flex-row md:justify-between"><div><span class="text-primary-text block font-bold">Previous</span>
<a href=https://bobblelaw.github.io/posts/multi-level-break/ class=block>Multi-Level Break in C++ via IIFE</a></div><div class="mt-4 md:mt-0 md:text-right"><span class="text-primary-text block font-bold">Next</span>
<a href=https://bobblelaw.github.io/posts/understanding-automatic-differentiation/ class=block>Understanding Automatic Differentiation</a></div></div></div></div><script>document.addEventListener("DOMContentLoaded",()=>{hljs.highlightAll()})</script></div></div></main><footer class=pl-scrollbar><div class="mx-auto w-full max-w-screen-xl"><div class="text-center p-6 pin-b"><p class="text-sm text-tertiary-text">&copy; 2022 <a href=#>Bobble Law</a> and <a href=#>Stay Inc.</a>
&#183; Powered by the <a href=https://github.com/wangchucheng/hugo-eureka class=hover:text-eureka>Eureka</a> theme for <a href=https://gohugo.io class=hover:text-eureka>Hugo</a></p></div></div></footer></body></html>